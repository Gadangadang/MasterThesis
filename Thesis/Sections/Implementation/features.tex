\section{The dataset features}

\subsection*{The Rapidity-Mass matrix (RMM)}\label{sec:rmm}
Most of the features in the analysis are elements in the Rapidity-Mass matrix (RMM) inspired by the work of Chekanov
\cite{Chekanov_2019}. The RMM is a convenient structure to create a feature space for the dataset. It contains 
information of various reconstructed objects and their combinations about mass, rapidity, momenta and missing transverse 
energy, all of which are useful in searches for new physics in HEP\cite{Chekanov_2021}. One example of an analysis 
that has used some features from the RMM is demontrated in \cite{Santos_2017}. The main reason however for 
using this structure is the systematic layout and automated featurespace, that maintains low to no correlation between 
the cells in the matrix, which is optimal when using neural networks. \par
The RMM is determined as a square matrix of $1 + \sum_{i=1}^{T}N_i$ columns and rows, where T is the total 
number of objects (i.e. jets, electrons etc.), and $N_i$ is the multiplicity of a given object. In the case where the 
multiplicity of a particle is equal to the number of different particles, we can denote the RMM matrix as a TmNn matrix, where m 
is the number of objects, and n is the multiplicity of each object. One should already here choose appropriately 
the number of objects and the multiplicity of each, as the computation time increases significantly 
when expanding the RMM. Each cell in the matrix contains information about either single or two particle properties. 
It is also important to remember that each event gets its own RMM, therefor each event creates its own signature that 
the autoencoder hopefully can learn trends from. An example of a small RMM is shown in matrix \ref{eq:rmmmatrix}.

\begin{equation}\label{eq:rmmmatrix}
\begin{pmatrix}
    \boldsymbol{e}_{T}^{miss} & m_T(j_1) & m_T(j_2) &  m_T(e_1) &  m_T(e_2)\\
    h_L(j_1) & \boldsymbol{e_T}(j_1) & m(j_1, j_2) & m(j_1, e_1) & m(j_1, e_2)\\
    h_L(j_2) & h(j_2, j_1) & \delta \boldsymbol{e_T}(j_2)& m(j_2, e_1) & m(j_2, e_2)\\
    h_L(e_1) & h(e_1, j_1) & h(e_1, j_2) & \boldsymbol{e_T}(e_1) & m(e_1, e_2)\\
    h_L(e_2) & h(e_2, j_1) & h(e_2, j_2) & h(e_2, e_1) & \delta \boldsymbol{e_T}(e_2)\\
\end{pmatrix}
\end{equation}
\newline
In matrix \ref{eq:rmmmatrix} we have the RMM matrix for a T2N2 system, in other words we have two types of objects, jets
\footnote{Jets here can both be b- or l-jets. Ljet is defined as jets with jetdl1r < 0.665, whereas bjet77 is defined as jets with jetdl1r>=2.195. 
jetdl1r is a machine learning output from a network trained to distinguish b- and ljets.} and electrons, and for ach ogjct we consider a multiplicity of two. 
The matrix itself is partitioned into three parts. 
The diagonal represents energy properties, the upper triangle represents mass properties and the lower triangle represents longitudal 
properties related to rapidity. The diagonal has three different properties, $\boldsymbol{e_T^{miss}}$, $\boldsymbol{e_T}$ and $\delta\boldsymbol{e_T}$. 
$\boldsymbol{e_T^{miss}}$ is placed in the $(0,0)$ position in the matrix. It accounts for the missing transverse energy of the system, which is of 
high interest for analyses in searches for BSM physics such as heavy neutrinos. $\boldsymbol{e_T}$ is the transverse energy defined as 

\begin{equation}\label{eq:et}
    \boldsymbol{e_T} = \sqrt{m^2 + p_T^2}
\end{equation}
but for light particles such as electrons, this can be approximated to $\boldsymbol{e_T} \approx p_T$. $\delta\boldsymbol{e_T}$ 
is the transverse energy imbalance. It is defined as 
\begin{equation}\label{eq:deltaet}
    \delta\boldsymbol{e_T} = \frac{E_T(i_{n-1}) - E_T(i_n)}{E_T(i_{n-1}) + E_T(i_n)}, \, n = 2, ..., N,
\end{equation}
where $i_n$ is the nth entry of object i. The first column in the RMM matrix, except the first element, is related to the 
longitudal property of the given particle. It is defined as
\begin{equation*}
    h_L(i_n) = C(\cosh{(y(i_n))} - 1).
\end{equation*}
C is a constant to ensure that the average $h_L(i_n)$ values do not deviate too much from the ranges of the invariant masses 
or the transverse masses, found to be $0.15$, as it ensures that rapidity ranges in the range $[-2.5, 2.5]$ produces $h_L(i_n)$ values in the 
$[0,1]$ interval\cite{Chekanov_2019}. $y(i_n)$ is the rapidity of the particle, and $i_n$ is the particle number. 
In the lower triangle we have the longitudal properties of the combinations of particles. Similar to $h_L(i_n)$, this property is defined as 
\begin{equation*}
    h(i_n, j_k) = C(\cosh{(\Delta y)} - 1),
\end{equation*}
where $\Delta y = y_{i_n} - y_{j_k}$ is the rapidity difference between particle $i_n$ and $j_k$. 


\subsection*{Tabular and sparse data}
A consequence of using the RMM structure is that the RMM for the data and SM MC can be sparse for some events. This is due to the fact that the RMM allows for 
the variety of final states of the reconstructed events, i.e. that one event has two ljets, zero bjets, one electron and two muons, whereas another 
event can have four ljets, three bjets and three electrons. This means that the non-zero elements of the RMM wil vary from event to event, 
and for neural networks this is a problem. To solve this problem, Chekanov simply pads the missing values with zeros\cite{Chekanov_2019}. 

\subsection*{Standard Model Monte Carlo and data comparison}\label{sec:mcdatacomp}

Before we can start the analysis, we need to compare the SM MC and data. This is done to ensure that the measured features used 
are well modelled by the SM MC training samples we use. As described by R. Stuart Geiger et al. \cite{DBLP:journals/corr/abs-2107-02278}, the concept of "Garbage 
in, garbage out" is of key importance in computer science, and is indeed important in high energy physics. To ensure that the models 
we train actually learn physical processes, the training set must closely rememble the data. The SM MC simulations are indeed very good, 
but they are numerical approximations and can 
sometimes be off. Thus, every feature that will be used for training must be checked before being used. This is done by 
comparing the distributions of the features in the SM MC and ATLAS data. Monte Carlo simulations are based on the actual theory 
itself, and comparisons with data taken from ATLAS and other detectors alike are neccesary to ensure that the SM background 
events look like data. This is done by creating control regions were there with high confidence is no signatures of New Physics. 
This of course becomes problematic if the New Physics are embedded in the background.\par
Now, if we compare all SM MC and ATLAS data, we would usually expect there to be a good agreement. To ensure that the SM MC actually 
represents the physics, we create signal and background regions to optimize for amount of signal and amount of background. If we can 
create a background region where we believe with very high certainty that only SM processes can occur, and we get a good match, 
we usually conclude that the SM MC is good enough. Since the data from ATLAS used in the work for this thesis has been thoroughly 
analysed for New Physics without finding any, it is not needed here to create these control regions. Traditional searches using 
rectangular cuts have only excluded some models, which is why machine learning is getting more popular. The hope is that the signal, 
whatever it might be, can be revealed with more clever feature engineering and smart machine learning algorithms. 
Particle physics differs here from more day-to-day machine learning as the recorded data from ATLAS, the true data, is completely 
unlabeled. 


\begin{figure}[H]
    \centering
    \begin{subfigure}{.6\textwidth}
        \includegraphics[width=\textwidth]{Figures/MC_Data_comp/lep3/e_T_miss_3lep.pdf}
        \caption{Missing transverse energy for the three lepton final state in GeV. The histogram contains the entire Run 2 dataset.}
        \label{fig:etmiss}
    \end{subfigure}
    \hfill
    \begin{subfigure}{.6\textwidth}
        \includegraphics[width=\textwidth]{Figures/MC_Data_comp/lep3/m_ele_0_ele_1_3lep.pdf}
        \caption{Invariant mass for the first and second electron in GeV. The histogram contains the entire Run 2 dataset. }
        \label{fig:mll_3lep}
    \end{subfigure}
    \hfill        
    \caption[3 lepton + $e_T^{miss}$ Monte Carlo and ATLAS data comparison]{Comparison of the Monte Carlo and data for the three lepton + $e_T^{miss}$ final state with the features $e_{T}^{miss}$ and flavor composition.
    }
    \label{fig:MC_Data_comp}
\end{figure}

In figure \ref{fig:MC_Data_comp} two features have been selected to vizualize the comparison between SM MC and ATLAS data, $e_T^{miss}$ 
and $m(ele_0, ele_1)$ in the 3 lepton + $e_T^{miss}$ dataset. The $e_T^{miss}$ and $m(ele_0, ele_1)$ shows a ratio between SM MC and ATLAS data reasonably close to 1, thus we can safely 
move forward with the analysis. All features were checked, and can be found in the GitHub repository for this thesis at 
\href{https://github.com/Gadangadang/MasterThesis/tree/main}{Figures/Histo\_var\_check}\footnote{Full link: \href{https://github.com/Gadangadang/MasterThesis/tree/main/Figures/histo_var_check/LEP3}{$https://github.com/Gadangadang/MasterThesis/tree/main/Figures/histo\_var\_check/LEP3$}} under the 3lep folder.Â \par 

\begin{figure}[H]
    \centering
    \begin{subfigure}{.6\textwidth}
        \includegraphics[width=\textwidth]{Figures/MC_Data_comp/lep2/e_T_miss_2lep.pdf}
        \caption{Missing transverse energy for the three lepton final state in GeV. The histogram contains the entire Run 2 dataset.}
        \label{fig:etmiss_2lep}
    \end{subfigure}
    \hfill
    \begin{subfigure}{.6\textwidth}
        \includegraphics[width=\textwidth]{Figures/MC_Data_comp/lep2/m_ele_0_ele_1_2lep.pdf}
        \caption{Invariant mass for the first and second electron in GeV. The histogram contains the entire Run 2 dataset. Note the sharp reduction of events from 10-70 GeV.}
        \label{fig:mll_2lep}
    \end{subfigure}
    \hfill        
    \caption[2 lepton + $e_T^{miss}$ Monte Carlo and ATLAS data comparison]{Comparison of the SM MC and data for the 2 lepton + $e_T^{miss}$ final 
    state with the features $e_{T}^{miss}$ and flavor composition. In figure \ref{fig:mll_2lep} a cut on the invariant mass above 70 GeV of the leading lepton
    pair. In some cases the first and second electron are not the leading pair, thus there will be some events in this histogram below 70 GeV. 
    }
    \label{fig:MC_Data_comp_2lep}
\end{figure}

Similar checks were done for the 2 lepton + $e_T^{miss}$ dataset. In figure \ref{fig:MC_Data_comp_2lep} the features $e_T^{miss}$ and $m(ele_0, ele_1)$ 
do not satisfy the same ratio between SM MC and ATLAS data, as with the 3 lepton + $e_T^{miss}$ case. It appears that RDataframe struggles with some diboson events, 
leading to a discrepency. This could be a trigger matching issue or an issue with RDataFrame. The samples were run using both C++ ROOT event selection and RDataFrame by one of the supervisors, and the 
issue seems to only occure with RDataFrame. Therefor all results regarding the 2 lepton + $e_T^{miss}$ dataset should be interpreted with this in mind. One attempt can be shown in 
figure \ref{fig:mll_2lep} where a cut on the invariant mass above 70 GeV of at least the two leptons with the highest energy was done to try to acommodate the trigger issue. 
It did not seem to work, and we proceded with the dataset. All features were checked, and can be found in the GitHub repository for this thesis at 
\href{https://github.com/Gadangadang/MasterThesis/tree/main}{Figures/Histo\_var\_check}\footnote{Full link: \href{https://github.com/Gadangadang/MasterThesis/tree/main/Figures/histo_var_check/LEP2}{$https://github.com/Gadangadang/MasterThesis/tree/main/Figures/histo\_var\_check/LEP2$}} under the 2lep folder.



\subsubsection*{Triggers }\label{sec:triggers}

The triggers used in the 2 lepton + $e_T^{miss}$  and 3 lepton + $e_T^{miss}$ dataset are datasets are shown in Table 
\ref{tab:triggers2015}, \ref{tab:triggers2016}, \ref{tab:triggers2017} and \ref{tab:triggers2018} for the 2015, 2016, 2017 and 2018 data taking periods.


\begin{table}[H]
    \centering
    
    \begin{tabular}{|l|l|}
    \hline
                          & \multicolumn{1}{c|}{Name}              \\ \hline
    \multirow{6}{*}{2015} & $HLT\_2e15\_lhvloose\_nod0\_L12EM13VH$ \\ \cline{2-2} 
                          & $HLT\_2e12\_lhloose\_L12EM10VH$          \\ \cline{2-2} 
                          & $HLT\_2mu10$                           \\ \cline{2-2} 
                          & $HLT\_mu18\_mu8noL1$                   \\ \cline{2-2} 
                          & $HLT\_e17\_lhloose\_mu14$              \\ \cline{2-2} 
                          & $HLT\_e7\_lhmedium\_mu24$              \\ \hline
    \end{tabular}
    \caption[2015 triggers table]{Triggers used in the 2015 SM MC and ATLAS data samples for the 2 lepton 0 $e_T^{miss}$ dataset.}
    \label{tab:triggers2015}
    \end{table}



\begin{table}[H]
    \centering
    
    \begin{tabular}{|l|l|}
    \hline
                          & Name  \\ \hline
    \multirow{9}{*}{2016} & $HLT\_2e15\_lhvloose\_nod0\_L12EM13VH$                 \\ \cline{2-2} 
                          & $HLT\_2e17\_lhvloose\_nod0$                   \\ \cline{2-2} 
                          & $HLT\_2mu10$                  \\ \cline{2-2} 
                          & $HLT\_2mu14$                  \\ \cline{2-2} 
                          & $HLT\_mu20\_mu8noL1$                  \\ \cline{2-2} 
                          & $HLT\_mu22\_mu8noL1$                 \\ \cline{2-2} 
                          & $HLT\_e17\_lhloose\_nod0\_mu14$                   \\ \cline{2-2} 
                          & $HLT\_e24\_lhmedium\_nod0\_L1EM20VHI\_mu8noL1$                  \\ \cline{2-2} 
                          & $HLT\_e7\_lhmedium\_nod0\_mu24$                   \\ \hline
    \end{tabular}
    \caption[2016 triggers table]{Triggers used in the 2016 SM MC and ATLAS data samples for the 2 lepton 0 $e_T^{miss}$ dataset.}
    \label{tab:triggers2016}
    \end{table}




\begin{table}[H]
    \centering
    
    \begin{tabular}{|l|l|}
    \hline
                            & Name  \\ \hline
    \multirow{7}{*}{2017} & $HLT\_2e17\_lhvloose\_nod0\_L12EM15VHI$                   \\ \cline{2-2} 
                            & $HLT\_2e24\_lhvloose\_nod0$                     \\ \cline{2-2} 
                            & $HLT\_2mu14$                  \\ \cline{2-2} 
                            &  $HLT\_mu22\_mu8noL1$                 \\ \cline{2-2} 
                            &  $HLT\_e17\_lhloose\_nod0\_mu14$                \\ \cline{2-2} 
                            &   $HLT\_e26\_lhmedium\_nod0\_mu8noL1$                \\ \cline{2-2} 
                            
                            & $HLT\_e7\_lhmedium\_nod0\_mu24$      \\ \hline
    \end{tabular}
    \caption[2017 triggers table]{Triggers used in the 2017 SM MC and ATLAS data samples for the 2 lepton 0 $e_T^{miss}$ dataset.}
    \label{tab:triggers2017}
    \end{table}


\begin{table}[H]
    \centering
    
    \begin{tabular}{|l|l|}
    \hline
                            & Name  \\ \hline
    \multirow{7}{*}{2018} & $HLT\_2e17\_lhvloose\_nod0\_L12EM15VHI$                   \\ \cline{2-2} 
                            & $HLT\_2e24\_lhvloose\_nod0$                     \\ \cline{2-2} 
                            & $HLT\_2mu14$                  \\ \cline{2-2} 
                            &  $HLT\_mu22\_mu8noL1$                  \\ \cline{2-2} 
                            &  $HLT\_e17\_lhloose\_nod0\_mu14$                \\ \cline{2-2} 
                            &   $HLT\_e26\_lhmedium\_nod0\_mu8noL1$                 \\ \cline{2-2} 
                            
                            & $HLT\_e7\_lhmedium\_nod0\_mu24$     \\ \hline
    \end{tabular}
    \caption[2018 triggers table]{Triggers used in the 2018 SM MC and ATLAS data samples for the 2 lepton 0 $e_T^{miss}$ dataset.}
    \label{tab:triggers2018}
    \end{table}

Each trigger is designed to detect certain base expectations in the detector, for example reconstructed leptons. In the tables above,
the triggers are laid out, showing which were used for a given data taking year. For a more in-depth understanding of trigger, 
it is recommended to look at the "Performance of the ATLAS Trigger System in 2015" paper\cite{triggersystem}, as well as the paper 
for the electron and photon triggers paper\cite{elec_photon} and the muon trigger paper\cite{muon}. The most important thing to note 
about these triggers is that the second argument in the trigger, in other words the component after "HLT\_" indicates the 
leptons and their transverse momentum criteria. The trigger "HLT\_2mu14" requires two reconstructed muons with a transverse momentum 
of at least 14 GeV to be triggered for a given event. The other components in some other triggers are more complicated, and 
describe reconstruction quality working points and more. \par 
For the 3 lepton + $e_T^{miss}$ final state, applying the trigger system on the data did not work as expected, thus a simple cut of requiring 
at least two leptons with a $p_T$ above 20 GeV was implemented. Note that further triggers would refine the dataset even more. 








