\section{The dataset features}

\subsection*{The Rapidity-Mass matrix (RMM) }\label{sec:rmm}
Most of the features in the analysis are elements in the so called Rapidity-Mass matrix (RMM)  inspired by the work of Chekanov \cite{Chekanov_2019}.
\par
The RMM is a convenient structure to create a feature space for the dataset. It contains information of various reconstructed objects and their combinations 
about mass, rapidity, momenta and missing transverse energy, all of which are useful in searches for new physics\cite{Chekanov_2021} in HEP. 
One example of an analysis that have used some of the features from the RMM is demontrated in \cite{Santos_2017}. The main reason however 
for using this structure is the systematic layout and automated featurespace, that maintains low to no corrolation between the cells in the 
matrix, as this is ideal when using neural networks.
\par
Its composition is determined as a square matrix of $1 + \sum_{i=1}^{T}N_i$ columns and rows, where T is the total number of objects (i.e jets, 
electrons etc.), and $N_i$ is the multiplicity of a given object. In the case of the same number of a given object for all objects, we can 
denote the RMM matrix as a TmNn matrix, where m is the multiplicity of T, and n is the number of particle per type. Thus there is already 
room for evaluation, as the combination of number of objects and the number of each object type highly affects the analysis as well as 
computational resources. Each cell in the matrix contains information about either single og two particle properties. This could in principle be
generalized to three particle properties, which would make a three dimensional RMM. The scope of thesis will for simplicity only cover the 
two dimensional case. An example is 
shown in matrix \ref{eq:rmmmatrix}.

\begin{equation}\label{eq:rmmmatrix}
\begin{pmatrix}
    \boldsymbol{e}_{T}^{miss} & m_T(j_1) & m_T(j_2) &  m_T(e_1) &  m_T(e_2)\\
    h_L(j_1) & \boldsymbol{e_T}(j_1) & m(j_1, j_2) & m(j_1, e_1) & m(j_1, e_2)\\
    h_L(j_2) & h(j_2, j_1) & \delta \boldsymbol{e_T}(j_2)& m(j_2, e_1) & m(j_2, e_2)\\
    h_L(e_1) & h(e_1, j_1) & h(e_1, j_2) & \boldsymbol{e_T}(e_1) & m(e_1, e_2)\\
    h_L(e_2) & h(e_2, j_1) & h(e_2, j_2) & h(e_2, e_1) & \delta \boldsymbol{e_T}(e_2)\\
\end{pmatrix}
\end{equation}

In matrix \ref{eq:rmmmatrix} we have the RMM matrix for a T2N2 system, in other words we have two types of particles, jets
\footnote{Jets here can both be b- or ljets. Ljet is defined as jets with jetdl1r < 0.665, where as bjet77 is defined as jets with jetdl1r>=2.195, 
where jetdl1r is a machine learning output from a network trained to destinguish b- and ljets.} and electrons, where each type has two particles. 
The matrix itself is partitioned into three parts. 
The diagonal represents energy properties, the upper triangular represents mass properties, and the lower triangular represents longitudal 
properties related to rapidity. The diagonal has three different properties, $\boldsymbol{e_T^{miss}}$, $\boldsymbol{e_T}$ and $\delta\boldsymbol{e_T}$. 
$\boldsymbol{e_T^{miss}}$ is placed in the $(0,0)$ position in the matrix. It accounts for the missing transverse energy for the system, which is of 
high interest for this analysis due to the search for heavy neutrinos. $\boldsymbol{e_T}$ is the transverse energy defined as 

\begin{equation}\label{eq:et}
    \boldsymbol{e_T} = \sqrt{m^2 + p_T^2}
\end{equation}
but for light particles such as electrons, this can be approximated to $\boldsymbol{e_T} \approx p_T$. $\delta\boldsymbol{e_T}$ 
is the transverse energy imbalance. It is defined as 
\begin{equation}\label{eq:deltaet}
    \delta\boldsymbol{e_T} = \frac{E_T(i_n-1) - E_T(i_n)}{E_T(i_n-1) + E_T(i_n)}, \, n = 2, ..., N.
\end{equation}
The first columm in the RMM matrix, with the exeption of the first element, is related to the longitudal property of the given particle. 
It is defined as
\begin{equation*}
    h_L(i_n) = C(\cosh{(y)} - 1),
\end{equation*}
where C is a constant to ensure that the average $h_L(i_n)$ values do not deviate too much from the ranges of the invariant masses 
of the transverse masses, found to be $0.15$, as it ensures that rapidity ranges in the range $[-2.5, 2.5]$ produces $h_L(i_n)$ values in the 
$[0,1]$ interval\cite{Chekanov_2019}. y is the rapidity of the particle, and $i_n$ is the particle number. 
On the lower triangle we have the longitudal properties of the combinations of particles. Similar to $h_L(i_n)$, this property is defined as 
\begin{equation*}
    h(i_n, j_k) = C(\cosh{(\Delta y)} - 1),
\end{equation*}
where $\Delta y = y_{i_n} - y_{j_k}$ is the rapidity difference for particle $i_n$ and $j_k$. 

\subsection*{Implementation of the RMM matrix}
An example of the RMM matrices used in this thesis is shown in figure \ref{fig:rmm_singular_events} below:


\begin{figure}[h!]
    \centering
    \begin{subfigure}{.8\textwidth}
        \includegraphics[width=\textwidth]{Figures/rmms/rmm_event_6993776_diboson4L.pdf}
        \caption{RMM matrix for event number 6993776 from the MonteCarlo diboson4L sample. Each feature is scaled based on a fit for that feature for 
        all events in the training set ($\approx 80\%$ of total MC). This sample contains two ljets, one electron and two muons.}
        \label{fig:rmm_zee_event}
    \end{subfigure}
    \hfill
    \begin{subfigure}{.8\textwidth}
        \includegraphics[width=\textwidth]{Figures/rmms/rmm_event_11739638_higgs.pdf}
        \caption{ RMM matrix for event number 11739638 from the MonteCarlo Higgs sample. Each feature is scaled based on a fit for that feature for 
        all events in the training set ($\approx 80\%$ of total MC). This sample contains five ljets, one bjet, one electron and two muons. }
        \label{fig:rmm_higgs_event}
    \end{subfigure}
    \hfill        
    \caption{Note here that the y axis for the RMM's lack every other label, due to lack of space in the y axis of the plot. If looked more closely upon, one can see that 
    each figure have all RMM cells, just that the labels, which are identical to the x axis label, only show every other. Note also here that the labels only tell which particle are used for that row/column, i.e 
    in figure \ref{fig:rmm_higgs_event} in row 0 column 3 we have the invariant mass of the first and second ljet. }
    \label{fig:rmm_singular_events}
\end{figure}

In figure \ref{fig:rmm_singular_events} we see two RMM matrices created from two different channels in the MonteCarlo samples. 
This RMM is of type T4N5\footnote{T4 $\to$ 4 particle types: bjets, ljets, electrons and muons. N5 $\to$ 5 particles per 
particle type. Note here that we have 5 particles only for the leptons, and 6 particles for each of the types of jets.}. 
These RMM matrices have scaled the features that a minimum value less than $-3$ and or a maximum value of above $3$. These 
scalers were fitted to the specific value using the "$.fit\_transform()$" and "$.transform()$" functions from the 
Scikit-learn library\cite{scikit-learn}. For easier interpretability, the gray area corresponds to a missing value, 
leading to so called "islands" in the RMM matrix.

\subsection*{Tabular and sparce data}
A concequence of using the RMM structure is that the data and Monte Carlo are sparce. This is due to the fact that the RMM allows for 
the variaty of final states of the reconstructed events, i.e that one event has two ljets, zero bjets, one electron and two muons, where as another 
event can have 4 ljet, 3 bjets and three electrons. This means that the RMM matrix for each event will have a different size, 
and for neural networks this is a problem. To solve this problem, Chekanov simply pads the missing values with 0s\cite{Chekanov_2019}. 

\subsection*{MonteCarlo and data comparison}\label{sec:mcdatacomp}

Before we can start the analysis, we need to compare the MonteCarlo and data. This is done to ensure that the measured features used 
are reconstructed well by the MonteCarlo training samples we use. As described by R. Stuart Geiger et al. \cite{DBLP:journals/corr/abs-2107-02278}, the concept of "Garbage 
in, garbage out" is of key importance in computer science, and indeed important in high energy physics. To ensure that the models 
we train actually learn physical processes, the training set must represent the physics "status quo". If the training samples do 
not match the physical reality, we regard it, in the context of high energy physics, as garbage in, which will in turn give 
garbage out. The Monte Carlo standard model simulations are indeed very good, but they are numerical approximations, and can 
sometimes be off. Thus, every feature that will be used for training have to be checked before being used. This is done by 
comparing the distributions of the features in the MonteCarlo and ATLAS data. MonteCarlo simulations are based on the actual theory 
itself, and comparisons with data taken from ATLAS and other detectors alike are neccesary to prove that the standard model is a good model.

Now, if we compare all SM MonteCarlo and ATLAS data, we would usually expect there to be a good overlap. To ensure that the standard model 
MonteCarlo actualy represents the physics, we create signal and background regions to optimize for a signal and or background. If we can 
create a background region where we believe with very high certainty that only standard model processes can occur, and we get a good match, 
we usually conclude that the MonteCarlo is good enough. Now, for this thesis, simply comparing all ATLAS data to all standard model MonteCarlo
is enough, as this data batch has been analysed by the ATLAS collaboration for multiple years without finding any new physics, concluding 
that if the signals are there, they are too small for so called visual cuts. Traditional searches have only exluded some models, which is why 
machine learning is getting more popular. The hope is that the signal, whatever it might be, can be revealed with clever feature 
engineering and smart machine learning algorithms. Particle physics differs here from more day to day machine learning as the target data is 
unlabeled. 


\begin{figure}[h!]
    \centering
    \begin{subfigure}{.6\textwidth}
        \includegraphics[width=\textwidth]{Figures/MC_Data_comp/lep3/e_T_miss_3lep.pdf}
        \caption{Missing transverse energy for the three lepton final state. The histogram contains the entire Run 2 dataset.}
        \label{fig:etmiss}
    \end{subfigure}
    \hfill
    \begin{subfigure}{.6\textwidth}
        \includegraphics[width=\textwidth]{Figures/MC_Data_comp/lep3/m_ele_0_ele_1_3lep.pdf}
        \caption{Invariant mass for the first and second electron. The histogram contains the entire Run 2 dataset. }
        \label{fig:}
    \end{subfigure}
    \hfill        
    \caption{Comparison of the MonteCarlo and data for the three lepton final state with the features $e_{T}^{miss}$ and flavor composition.
    }
    \label{fig:MC_Data_comp}
\end{figure}

In figure \ref{fig:MC_Data_comp} two features have been selected to vizualize the comparison between Monte Carlo and ATLAS data, $e_T^{miss}$ 
and $m(ele_0, ele_1)$. We see that both $e_T^{miss}$ and$m(ele_0, ele_1)$ satisfy a good ratio between Monte Carlo and ATLAS data, thus we can safely 
move forward with the analysis. All features were checked, and can be found in the Github repository for this thesis under the folder 
\href{https://github.com/Gadangadang/MasterThesis/tree/main}{Figures/Histo\_var\_check}.
