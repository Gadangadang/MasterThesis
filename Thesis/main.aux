\relax 
\providecommand\zref@newlabel[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{JHEP}
\babel@aux{UKenglish}{}
\@writefile{toc}{\contentsline {chapter}{Introduction}{1}{chapter*.4}\protected@file@percent }
\citation{anom_detec}
\citation{anom_detec}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Machine learning}{3}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chap:MLphenom}{{1}{3}{Machine learning}{chapter.1}{}}
\newlabel{Chap:MLphenom@cref}{{[chapter][1][]1}{[1][3][]3}}
\citation{FYSSTK}
\citation{FYSSTK}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Simple neural network diagram drawm using Draw.io. Here the blue dots are the input layer, the green dots are a hidden layer, and the red dots are the output layer. The arrows shows the connections between each node. \relax }}{4}{figure.caption.8}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:nndiagram}{{1.1}{4}{Simple neural network diagram drawm using Draw.io. Here the blue dots are the input layer, the green dots are a hidden layer, and the red dots are the output layer. The arrows shows the connections between each node. \relax }{figure.caption.8}{}}
\newlabel{fig:nndiagram@cref}{{[figure][1][1]1.1}{[1][4][]4}}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Notation\relax }}{5}{table.caption.9}\protected@file@percent }
\newlabel{tab:notation}{{1.1}{5}{Notation\relax }{table.caption.9}{}}
\newlabel{tab:notation@cref}{{[table][1][1]1.1}{[1][4][]5}}
\@writefile{lot}{\contentsline {table}{\numberline {1.2}{\ignorespaces Table containing notation used for deriving the mathematical formulas for the neural network \cite  {FYSSTK}\relax }}{5}{table.caption.9}\protected@file@percent }
\citation{FYSSTK}
\citation{FYSSTK}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Figures showing different choice of learning rate for a given costfunction, with respect to the tunable parameters. Source: \href  {https://www.jeremyjordan.me/content/images/2018/02/Screen-Shot-2018-02-24-at-11.47.09-AM.png}{Jeremy Jordan}, accessed 03.10.22.\relax }}{6}{figure.caption.11}\protected@file@percent }
\newlabel{fig:lr_choice}{{1.2}{6}{Figures showing different choice of learning rate for a given costfunction, with respect to the tunable parameters. Source: \href {https://www.jeremyjordan.me/content/images/2018/02/Screen-Shot-2018-02-24-at-11.47.09-AM.png}{Jeremy Jordan}, accessed 03.10.22.\relax }{figure.caption.11}{}}
\newlabel{fig:lr_choice@cref}{{[figure][2][1]1.2}{[1][6][]6}}
\citation{backprop}
\citation{Goodfellow-et-al-2016}
\newlabel{eq:localgradient}{{1.3}{8}{Backpropagation}{equation.1.0.3}{}}
\newlabel{eq:localgradient@cref}{{[equation][3][1]1.3}{[1][8][]8}}
\newlabel{eq:dzl1dz}{{1.4}{8}{Backpropagation}{equation.1.0.4}{}}
\newlabel{eq:dzl1dz@cref}{{[equation][4][1]1.4}{[1][8][]8}}
\newlabel{eq:localgradient2}{{1.5}{8}{Backpropagation}{equation.1.0.5}{}}
\newlabel{eq:localgradient2@cref}{{[equation][5][1]1.5}{[1][8][]8}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Figure depicting a model for an image denoising autoencoder. Here the input $\bf  {x}$ is the original image, $\bf  {\tilde  {x}}$ is a noised version of $\bf  {x}$, $E$ is the encoder, $D$ is the decoder, and $c$ is the latent space. Found 27.09.22 \href  {https://miro.medium.com/max/720/0*ECdHu2yeal38Jl3P.png}{here}. \relax }}{9}{figure.caption.15}\protected@file@percent }
\newlabel{fig:ae_denoise}{{1.3}{9}{Figure depicting a model for an image denoising autoencoder. Here the input $\bf {x}$ is the original image, $\bf {\tilde {x}}$ is a noised version of $\bf {x}$, $E$ is the encoder, $D$ is the decoder, and $c$ is the latent space. Found 27.09.22 \href {https://miro.medium.com/max/720/0*ECdHu2yeal38Jl3P.png}{here}. \relax }{figure.caption.15}{}}
\newlabel{fig:ae_denoise@cref}{{[figure][3][1]1.3}{[1][8][]9}}
\newlabel{eq:loss_ae}{{1.6}{9}{Autoencoders}{equation.1.0.6}{}}
\newlabel{eq:loss_ae@cref}{{[equation][6][1]1.6}{[1][9][]9}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Standard model phenomenology}{11}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chap:SM}{{2}{11}{Standard model phenomenology}{chapter.2}{}}
\newlabel{Chap:SM@cref}{{[chapter][2][]2}{[1][11][]11}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces The standard model of elementary particles. Source \href  {https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Standard_Model_of_Elementary_Particles.svg/1200px-Standard_Model_of_Elementary_Particles.svg.png}{here}. Accessed 07.10.22\relax }}{12}{figure.caption.17}\protected@file@percent }
\newlabel{fig:smdiagram}{{2.1}{12}{The standard model of elementary particles. Source \href {https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Standard_Model_of_Elementary_Particles.svg/1200px-Standard_Model_of_Elementary_Particles.svg.png}{here}. Accessed 07.10.22\relax }{figure.caption.17}{}}
\newlabel{fig:smdiagram@cref}{{[figure][1][2]2.1}{[1][11][]12}}
\citation{collaboration_2020}
\citation{Owen:2302730}
\citation{Wang:2707056}
\citation{Bernius:2707054}
\citation{Wang:2707056}
\citation{Wang:2707056}
\citation{ROOT}
\citation{Manca:2694107}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Implementation}{13}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chap:implementation}{{3}{13}{Implementation}{chapter.3}{}}
\newlabel{Chap:implementation@cref}{{[chapter][3][]3}{[1][13][]13}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Figure describing the steps to take for data collection at ATLAS, fetched from \href  {https://indico.cern.ch/event/1159574/timetable/?view=standard}{Hybrid ATLAS Induction Day + Software Tutorial workshop}, part \href  {https://indico.cern.ch/event/860971/contributions/3672974/attachments/1972049/3280896/Atlas_computing_data_preparation_jan20.pdf}{Computing and Data preparation}, held by S.M Wang \cite  {Wang:2707056} . \relax }}{14}{figure.caption.29}\protected@file@percent }
\newlabel{fig:atlas_data_col_phys}{{3.1}{14}{Figure describing the steps to take for data collection at ATLAS, fetched from \href {https://indico.cern.ch/event/1159574/timetable/?view=standard}{Hybrid ATLAS Induction Day + Software Tutorial workshop}, part \href {https://indico.cern.ch/event/860971/contributions/3672974/attachments/1972049/3280896/Atlas_computing_data_preparation_jan20.pdf}{Computing and Data preparation}, held by S.M Wang \cite {Wang:2707056} . \relax }{figure.caption.29}{}}
\newlabel{fig:atlas_data_col_phys@cref}{{[figure][1][3]3.1}{[1][13][]14}}
\newlabel{code:python_func_example}{{3}{15}{}{lstlisting.3.-1}{}}
\newlabel{code:python_func_example@cref}{{[chapter][3][]3}{[1][15][]15}}
\newlabel{code:cpp_func_example}{{3}{15}{}{lstlisting.3.-2}{}}
\newlabel{code:cpp_func_example@cref}{{[chapter][3][]3}{[1][15][]15}}
\citation{hdf5}
\citation{Chekanov_2019}
\newlabel{code:python_func_example}{{3}{16}{}{lstlisting.3.-3}{}}
\newlabel{code:python_func_example@cref}{{[chapter][3][]3}{[1][16][]16}}
\newlabel{eq:rmmmatrix}{{3.1}{16}{RMM matrix}{equation.3.0.1}{}}
\newlabel{eq:rmmmatrix@cref}{{[equation][1][3]3.1}{[1][16][]16}}
\citation{tensorflow2015-whitepaper}
\citation{chollet2015keras}
\citation{omalley2019kerastuner}
\citation{hyperband:opt}
\citation{ADAM:opti}
\citation{scikit-learn}
\citation{Hunter:2007}
\citation{Waskom2021}
\citation{plotly}
\citation{harris2020array}
\citation{reback2020pandas}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Results}{19}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chap:results}{{4}{19}{Results}{chapter.4}{}}
\newlabel{Chap:results@cref}{{[chapter][4][]4}{[1][19][]19}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Discussion}{21}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chap:discussion}{{5}{21}{Discussion}{chapter.5}{}}
\newlabel{Chap:discussion@cref}{{[chapter][5][]5}{[1][21][]21}}
\@writefile{toc}{\contentsline {chapter}{Conclusion}{23}{chapter*.39}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Appendices}{25}{section*.40}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Appendix A}{27}{appendix*.41}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{Appendix B}{29}{appendix*.42}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{Appendix C}{31}{appendix*.43}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibdata{bibliography.bib}
\@writefile{toc}{\contentsline {chapter}{Appendix D}{33}{appendix*.44}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{anom_detec}{{1}{}{{}}{{}}}
\bibcite{FYSSTK}{{2}{}{{}}{{}}}
\bibcite{backprop}{{3}{}{{}}{{}}}
\bibcite{Goodfellow-et-al-2016}{{4}{}{{}}{{}}}
\bibcite{collaboration_2020}{{5}{}{{}}{{}}}
\bibcite{Owen:2302730}{{6}{}{{}}{{}}}
\bibcite{Wang:2707056}{{7}{}{{}}{{}}}
\bibcite{Bernius:2707054}{{8}{}{{}}{{}}}
\bibcite{ROOT}{{9}{}{{}}{{}}}
\bibcite{Manca:2694107}{{10}{}{{}}{{}}}
\bibcite{hdf5}{{11}{}{{}}{{}}}
\bibcite{Chekanov_2019}{{12}{}{{}}{{}}}
\bibcite{tensorflow2015-whitepaper}{{13}{}{{}}{{}}}
\bibcite{chollet2015keras}{{14}{}{{}}{{}}}
\bibcite{omalley2019kerastuner}{{15}{}{{}}{{}}}
\bibcite{hyperband:opt}{{16}{}{{}}{{}}}
\bibcite{ADAM:opti}{{17}{}{{}}{{}}}
\bibcite{scikit-learn}{{18}{}{{}}{{}}}
\bibcite{Hunter:2007}{{19}{}{{}}{{}}}
\bibcite{Waskom2021}{{20}{}{{}}{{}}}
\bibcite{plotly}{{21}{}{{}}{{}}}
\bibcite{harris2020array}{{22}{}{{}}{{}}}
\bibcite{reback2020pandas}{{23}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\gdef \@abspage@last{47}
